{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with Ensemble Method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les scores obtenus avec la regression logistique pour les différentes catégories étaient les suivants :\n",
    "- f1 score pour la category_1 : 0.1601514910747391\n",
    "- f1 score pour la category_2 : 0.6212450536216092\n",
    "- f1 score pour la category_3 : 0.7704773846842813\n",
    "- f1 score pour la category_4 : 0.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là où la regression logistique semble assez bien performée sur la catégorie 3, elle n'est d'aucune utilité pour prédire la catégorie 4. Nous allons donc essayer d'améliorer ces résultats en utilisant d'autres méthodes et prendre le meilleur classificateur pour chaque catégorie"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['category_1', 'category_2', 'category_3', 'category_4']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DIRECTORY = \"challenge_dataset/\"\n",
    "\n",
    "# extract data\n",
    "X_extract = pd.read_csv(DIRECTORY + 'X_train.csv', sep=';').drop(columns=['Id'])\n",
    "y = pd.read_csv(DIRECTORY + 'y_train.csv', sep=';').drop(columns=['Id'])\n",
    "\n",
    "categories = list(y.columns)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delan\\anaconda3\\lib\\site-packages\\spacy\\util.py:837: UserWarning: [W095] Model 'fr_core_news_md' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                       mourir heure revoir petit enfant\n",
       "1      maladie conséquence jeune génération voir situ...\n",
       "2                                       sortir mal loger\n",
       "3      inquiétude santé proche fragile femme battre e...\n",
       "4                       bien entendre contracter maladie\n",
       "                             ...                        \n",
       "480                                    forme grave civid\n",
       "481    inquiétude retrouver liberté action total limi...\n",
       "482    incertitude être voir petit fils jusque ruptur...\n",
       "483    inquiétude normal face épidémie crainte voir p...\n",
       "484                                   respecter barrière\n",
       "Length: 485, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def preprocess_data(data_input: pd.Series):\n",
    "    nlp = spacy.load('fr_core_news_md')\n",
    "\n",
    "    def tokenize(sentence):\n",
    "        doc = nlp(sentence)\n",
    "        return [token.lemma_ for token in doc if not (token.is_stop or token.is_punct or token.is_digit or '\\r\\n' in token.text)]\n",
    "\n",
    "    #tokenize data\n",
    "    tokens = [tokenize(sentence) for sentence in data_input]\n",
    "\n",
    "    return pd.Series(tokens)\n",
    "\n",
    "X = preprocess_data(X_extract['Caption'])\n",
    "X = X.apply(lambda x: ' '.join(x))\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naives Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score category_1 : 0.5661996032760153\n",
      "f1 score category_2 : 0.7225825317642476\n",
      "f1 score category_3 : 0.7862591827863508\n",
      "f1 score category_4 : 0.1042016806722689\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "n_splits = 5 # nombre de splits pour le KFold\n",
    "NB = make_pipeline(\n",
    "    CountVectorizer(ngram_range=(1,2)),\n",
    "    OneVsRestClassifier(MultinomialNB())\n",
    ")\n",
    "cv = KFold(n_splits, shuffle=True)\n",
    "for category in categories:\n",
    "    y_category = y[category]\n",
    "    print(\"f1 score\", category, \":\", np.mean(cross_val_score(NB, X, y_category, cv=cv, scoring='f1', error_score='raise')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score category_1 : 0.5419441428137081\n",
      "f1 score category_2 : 0.7275056248094575\n",
      "f1 score category_3 : 0.7784471290614864\n",
      "f1 score category_4 : 0.384949494949495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits = 10 # nombre de splits pour le KFold\n",
    "SVC = make_pipeline(\n",
    "    CountVectorizer(ngram_range=(1,2), min_df=3),\n",
    "    OneVsRestClassifier(LinearSVC())\n",
    ")\n",
    "cv = StratifiedKFold(n_splits, shuffle=True)\n",
    "for category in categories:\n",
    "    print(\"f1 score\", category, \":\", np.mean(cross_val_score(SVC, X, y[category], cv=cv, scoring='f1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score category_1 : 0.47407763439576805\n",
      "f1 score category_2 : 0.4282271356094885\n",
      "f1 score category_3 : 0.640858017304879\n",
      "f1 score category_4 : 0.2115151515151515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "n_splits = 10 # nombre de splits pour le KFold\n",
    "SVC = make_pipeline(CountVectorizer(ngram_range=(1,2)),\n",
    "    FunctionTransformer(lambda x: x.toarray()),\n",
    "    OneVsRestClassifier(LinearDiscriminantAnalysis())\n",
    ")\n",
    "cv = StratifiedKFold(n_splits, shuffle=True)\n",
    "for category in categories:\n",
    "    print(\"f1 score\", category, \":\", np.mean(cross_val_score(SVC, X, y[category], cv=cv, scoring='f1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score category_1 : 0.6153846153846153\n",
      "f1 score category_2 : 0.6\n",
      "f1 score category_3 : 0.7441860465116279\n",
      "f1 score category_4 : 0.09523809523809522\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "SVC = make_pipeline(CountVectorizer(),\n",
    "    OneVsRestClassifier(LinearSVC())\n",
    ")\n",
    "\n",
    "scores = []\n",
    "y_pred = pd.DataFrame()\n",
    "X_train\n",
    "SVC.fit(X_train, y_train['category_1'])\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "    SVC.fit(X_train, y_train[category])\n",
    "    y_pred[category] = SVC.predict(X_test)\n",
    "    scores.append(f1_score(y_test[category], y_pred[category]))\n",
    "for index, row in y_pred.iterrows():\n",
    "    if (row['category_1'] == 0) and (row['category_2'] == 0) and (row['category_3'] == 0):\n",
    "        row['category_4'] = 1\n",
    "scores[3] = f1_score(y_test['category_4'], y_pred['category_4'])\n",
    "for idx, category in enumerate(categories):\n",
    "    print(\"f1 score\", category, \":\", scores[idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utilisation de stopwords n'augmente pas les résultats, et other_stopwords diminue les résultats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score category_1 : 0.5038190414786159\n",
      "f1 score category_2 : 0.694308848501942\n",
      "f1 score category_3 : 0.7739567789021589\n",
      "f1 score category_4 : 0.17931623931623933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "n_splits = 5 # nombre de splits pour le KFold\n",
    "LR = make_pipeline(CountVectorizer(),\n",
    "    OneVsRestClassifier(LogisticRegression(solver='sag', max_iter=10000))\n",
    ")\n",
    "cv = KFold(n_splits, shuffle=True)\n",
    "for category in categories:\n",
    "    print(\"f1 score\", category, \":\", np.mean(cross_val_score(LR, X, y[category], cv=cv, scoring='f1')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le meilleur classificateur semble être le Linear SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score category_1 : 0.4285714285714285\n",
      "f1 score category_2 : 0.26666666666666666\n",
      "f1 score category_3 : 0.23076923076923075\n",
      "f1 score category_4 : 0.23255813953488372\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# extract labeled data\n",
    "X_labeled = pd.read_csv(DIRECTORY + 'X_train.csv', sep=';')\n",
    "X_labeled = X_labeled['Caption']\n",
    "y_labeled = pd.read_csv(DIRECTORY + 'y_train.csv', sep=';').drop(columns=['Id'])\n",
    "\n",
    "# extract unlabeled data\n",
    "X_unlabeled = pd.read_csv(DIRECTORY + 'nonlabeled_data.csv', sep=';')\n",
    "X_unlabeled = X_unlabeled['Caption']\n",
    "nb_unlabeled = X_unlabeled.shape[0]\n",
    "y_unlabeled = pd.DataFrame([[-1, -1, -1, -1] for i in range(nb_unlabeled)], columns=categories)\n",
    "\n",
    "# création du jeu d'entraînement et de test à partir des données labelisées\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.1)\n",
    "\n",
    "preprocess_pipeline = make_pipeline(\n",
    "    CountVectorizer(),\n",
    "    TfidfTransformer(),\n",
    "    FunctionTransformer(lambda x: x.toarray()),\n",
    ")\n",
    "model_pipeline = make_pipeline(\n",
    "    OneVsRestClassifier(LinearSVC())\n",
    ")\n",
    "X = pd.concat([X_train, X_unlabeled])\n",
    "X = preprocess_pipeline.fit_transform(X)\n",
    "X_test = preprocess_pipeline.transform(X_test)\n",
    "y = pd.concat([y_train, y_unlabeled])\n",
    "y_label_spread = pd.DataFrame()\n",
    "y_pred = pd.DataFrame()\n",
    "for category in categories:\n",
    "    ls = LabelSpreading()\n",
    "    ls.fit(X, y[category])\n",
    "    y_label_spread[category] = ls.transduction_\n",
    "    model_pipeline.fit(X, y_label_spread[category])\n",
    "    y_pred[category] = ls.predict(X_test)\n",
    "    print(\"f1 score\", category, \":\", f1_score(y_test[category], y_pred[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delan\\anaconda3\\lib\\site-packages\\spacy\\util.py:837: UserWarning: [W095] Model 'fr_core_news_md' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# extract labeled data\n",
    "X_labeled = pd.read_csv(DIRECTORY + 'X_train.csv', sep=';')\n",
    "X_labeled = preprocess_data(X_labeled['Caption'])\n",
    "X_labeled = X_labeled.apply(lambda x: ' '.join(x))\n",
    "\n",
    "y_labeled = pd.read_csv(DIRECTORY + 'y_train.csv', sep=';').drop(columns=['Id'])\n",
    "\n",
    "# extract unlabeled data\n",
    "X_unlabeled = pd.read_csv(DIRECTORY + 'nonlabeled_data.csv', sep=';')\n",
    "X_unlabeled = preprocess_data(X_unlabeled['Caption'])\n",
    "X_unlabeled = X_unlabeled.apply(lambda x: ' '.join(x))\n",
    "nb_unlabeled = X_unlabeled.shape[0]\n",
    "y_unlabeled = pd.DataFrame([[-1, -1, -1, -1] for i in range(nb_unlabeled)], columns=categories)\n",
    "\n",
    "\n",
    "SVC_pipeline = make_pipeline(\n",
    "    CountVectorizer(ngram_range=(1,2), min_df=3),\n",
    "    TfidfTransformer(),\n",
    "    SelfTrainingClassifier(SVC(kernel='linear', probability=True))\n",
    ")\n",
    "y_pred = pd.DataFrame()\n",
    "n_splits = 5\n",
    "for category in categories:\n",
    "    score = 0\n",
    "    sss = StratifiedShuffleSplit(n_splits, test_size=0.1)\n",
    "    for train_idx, test_idx in sss.split(X_labeled, y_labeled[category]):\n",
    "        X_train = pd.concat([X_labeled[train_idx], X_unlabeled])\n",
    "        y_train = pd.concat([y_labeled[category][train_idx], y_unlabeled[category]])\n",
    "        SVC_pipeline.fit(X_train, y_train)\n",
    "        y_pred[category] = SVC_pipeline.predict(X_labeled[test_idx])\n",
    "        score += f1_score(y_labeled[category][test_idx], y_pred[category])\n",
    "    print(\"f1 score\", category, \":\", score/n_splits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction pour Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delan\\anaconda3\\lib\\site-packages\\spacy\\util.py:837: UserWarning: [W095] Model 'fr_core_news_md' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>category_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>603</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>604</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>798</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>799</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>801</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>802</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  category_1  category_2  category_3  category_4\n",
       "0    599           0           0           0           0\n",
       "1    600           0           0           0           0\n",
       "2    602           0           0           1           0\n",
       "3    603           0           1           0           0\n",
       "4    604           0           0           1           0\n",
       "..   ...         ...         ...         ...         ...\n",
       "152  798           0           1           0           1\n",
       "153  799           0           0           1           0\n",
       "154  800           1           0           0           0\n",
       "155  801           0           1           0           0\n",
       "156  802           1           0           0           0\n",
       "\n",
       "[157 rows x 5 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_test = pd.read_csv(DIRECTORY + 'X_test.csv', sep=';')\n",
    "index = X_test['Id']\n",
    "X_test = preprocess_data(X_test['Caption'])\n",
    "X_test = X_test.apply(lambda x: ' '.join(x))\n",
    "\n",
    "SVC = make_pipeline(\n",
    "    CountVectorizer(ngram_range=(1,2), min_df=3),\n",
    "    OneVsRestClassifier(LinearSVC())\n",
    ")\n",
    "y_pred = pd.DataFrame(index, columns=['Id'])\n",
    "for category in categories:\n",
    "    SVC.fit(X, y[category])\n",
    "    y_pred[category] = SVC.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    153\n",
       "1      4\n",
       "Name: category_3, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(DIRECTORY + 'X_test.csv', sep=';')\n",
    "index = X_test['Id']\n",
    "X_test = X_test['Caption']\n",
    "\n",
    "y_pred = pd.DataFrame(index, columns=['Id'])\n",
    "for category in categories:\n",
    "    y_pred[category] = SVC_pipeline.predict(X_test)\n",
    "y_pred['category_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv(\"results/y_linear_SVC_on_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b756f55fe797ce5a3b3491a8045903d781b4ca2e5e9dbd4284da291141e560b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
