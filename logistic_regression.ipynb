{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "656bf480",
   "metadata": {},
   "source": [
    "# NLP with Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2b9af3f",
   "metadata": {},
   "source": [
    "Les 4 différentes catégories sont :\n",
    "- peur pour eux\n",
    "- peur pour les autres\n",
    "- peur sur la gestion de la crise\n",
    "- fourre tout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da64b841",
   "metadata": {},
   "source": [
    "## Extraction et preprocessing des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7714f7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\delan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\delan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "c:\\Users\\delan\\anaconda3\\lib\\site-packages\\spacy\\util.py:837: UserWarning: [W095] Model 'fr_core_news_md' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmas</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[mourir, heure, plus, revoir, petit, enfant]</td>\n",
       "      <td>[VERB, NOUN, ADV, VERB, ADJ, NOUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[maladie, conséquence, jeune, génération, voir...</td>\n",
       "      <td>[NOUN, NOUN, ADJ, NOUN, VERB, NOUN, ADJ, NOUN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[sortir, mal, loger]</td>\n",
       "      <td>[VERB, ADV, VERB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[inquiétude, santé, proche, plus, fragile, fem...</td>\n",
       "      <td>[NOUN, ADJ, ADJ, ADV, ADJ, NOUN, VERB, NOUN, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[bien, entendre, contracter, maladie]</td>\n",
       "      <td>[ADV, VERB, VERB, NOUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>[forme, grave, civid]</td>\n",
       "      <td>[NOUN, ADJ, ADJ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>[inquiétude, retrouver, liberté, action, total...</td>\n",
       "      <td>[NOUN, VERB, NOUN, NOUN, ADJ, VERB, NOUN, NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>[incertitude, lequel, plus, voir, petit, fils,...</td>\n",
       "      <td>[NOUN, PRON, ADV, VERB, ADJ, NOUN, ADP, NOUN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>[inquiétude, normal, face, épidémie, crainte, ...</td>\n",
       "      <td>[NOUN, ADJ, NOUN, NOUN, NOUN, VERB, ADJ, NOUN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>[respecter, barrière]</td>\n",
       "      <td>[VERB, NOUN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>485 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                lemmas  \\\n",
       "0         [mourir, heure, plus, revoir, petit, enfant]   \n",
       "1    [maladie, conséquence, jeune, génération, voir...   \n",
       "2                                 [sortir, mal, loger]   \n",
       "3    [inquiétude, santé, proche, plus, fragile, fem...   \n",
       "4                [bien, entendre, contracter, maladie]   \n",
       "..                                                 ...   \n",
       "480                              [forme, grave, civid]   \n",
       "481  [inquiétude, retrouver, liberté, action, total...   \n",
       "482  [incertitude, lequel, plus, voir, petit, fils,...   \n",
       "483  [inquiétude, normal, face, épidémie, crainte, ...   \n",
       "484                              [respecter, barrière]   \n",
       "\n",
       "                                                   pos  \n",
       "0                   [VERB, NOUN, ADV, VERB, ADJ, NOUN]  \n",
       "1    [NOUN, NOUN, ADJ, NOUN, VERB, NOUN, ADJ, NOUN,...  \n",
       "2                                    [VERB, ADV, VERB]  \n",
       "3    [NOUN, ADJ, ADJ, ADV, ADJ, NOUN, VERB, NOUN, N...  \n",
       "4                              [ADV, VERB, VERB, NOUN]  \n",
       "..                                                 ...  \n",
       "480                                   [NOUN, ADJ, ADJ]  \n",
       "481  [NOUN, VERB, NOUN, NOUN, ADJ, VERB, NOUN, NOUN...  \n",
       "482  [NOUN, PRON, ADV, VERB, ADJ, NOUN, ADP, NOUN, ...  \n",
       "483  [NOUN, ADJ, NOUN, NOUN, NOUN, VERB, ADJ, NOUN,...  \n",
       "484                                       [VERB, NOUN]  \n",
       "\n",
       "[485 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from treat_data import treat_data\n",
    "\n",
    "DIRECTORY = \"challenge_dataset/\"\n",
    "\n",
    "# extract data\n",
    "X = pd.read_csv(DIRECTORY + 'X_train.csv', sep=';').drop(columns=['Id'])\n",
    "y = pd.read_csv(DIRECTORY + 'y_train.csv', sep=';').drop(columns=['Id'])\n",
    "\n",
    "# preprocessing data\n",
    "X_clean = pd.DataFrame()\n",
    "X_clean['lemmas'], X_clean['pos'] = treat_data(X)\n",
    "\n",
    "X_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c32084e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_1    135\n",
       "category_2    172\n",
       "category_3    237\n",
       "category_4     57\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b57d293",
   "metadata": {},
   "source": [
    "category_4 est une catégorie \"fourre-tout\". De plus, on possède moins de données sur cette catégorie que les autres. Il pourrais donc essayer d'entraîner le jeu de données sans prendre en compte cette catégorie, puis définir cette catégorie comme label par défaut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aca65529",
   "metadata": {},
   "source": [
    "## Mise en forme des données pour la regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84b03c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = X_clean['lemmas'].apply(lambda x: ' '.join(x)).to_list()\n",
    "labels = y.columns\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48b5e6a8",
   "metadata": {},
   "source": [
    "## Mise en place du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6129344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LOGISTIC_REGRESSION_PARAMETERS = {'C': 0.1,\n",
    "                                  'max_iter': 100}\n",
    "\n",
    "def fit_one_classifier(X, y):\n",
    "    classifier = LogisticRegression(**LOGISTIC_REGRESSION_PARAMETERS)\n",
    "    return classifier.fit(X, y)\n",
    "\n",
    "def fit_all_classifiers(X, y_full, labels):\n",
    "  classifiers = {}\n",
    "  for idx, label in enumerate(labels):\n",
    "      target = y_full[label]\n",
    "      classifier = fit_one_classifier(X, target)\n",
    "      classifiers[label] = classifier\n",
    "  return classifiers\n",
    "\n",
    "clfs = fit_all_classifiers(X, y, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5331f37f",
   "metadata": {},
   "source": [
    "## Score f1 du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3dbc0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score pour la category_1 : 0.1601514910747391\n",
      "f1 score pour la category_2 : 0.6212450536216092\n",
      "f1 score pour la category_3 : 0.7704773846842813\n",
      "f1 score pour la category_4 : 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def cross_val_score_classifier(X, y):\n",
    "  classifier = LogisticRegression(**LOGISTIC_REGRESSION_PARAMETERS)\n",
    "  cv_score = np.mean(cross_val_score(classifier, X, y, scoring='f1'))\n",
    "  return cv_score\n",
    "\n",
    "def compute_CV_score_for_each_class(X, y_full, labels):\n",
    "  scores = []\n",
    "  for label in labels:\n",
    "      target = y_full[label].values\n",
    "      cv_score = cross_val_score_classifier(X, target)\n",
    "      scores.append(cv_score)\n",
    "  return scores\n",
    "\n",
    "scores = compute_CV_score_for_each_class(X, y, labels)\n",
    "for idx in range(len(scores)):\n",
    "  print(\"f1 score pour la\", labels[idx], \":\", scores[idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "482d7c4c",
   "metadata": {},
   "source": [
    "Les résultats sont assez bons pour les catégories 2 et 3 mais très mauvais pour les catégories 1 et 4. Pour la catégorie 4 celà est peut-être dû au manque de données."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d73aa23",
   "metadata": {},
   "source": [
    "## Prédictions pour Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ebdae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data\n",
    "X = pd.read_csv(DIRECTORY + 'X_test.csv', sep=';')\n",
    "index = X['Id'] # save index for submission\n",
    "\n",
    "# preprocessing data\n",
    "X_clean = pd.DataFrame()\n",
    "X_clean['lemmas'], X_clean['pos'] = treat_data(X)\n",
    "X_clean.insert(0, 'Id', index)\n",
    "\n",
    "# vectorization\n",
    "corpus = X_clean['lemmas'].apply(lambda x: ' '.join(x)).to_list()\n",
    "X = vectorizer.transform(corpus)\n",
    "\n",
    "# prediction\n",
    "y_pred = pd.DataFrame.from_dict({label: clf.predict(X) for label, clf in clfs.items()})\n",
    "y_pred.insert(0, 'Id', index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beeb2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean.to_csv(\"challenge_dataset/X_test_clean.csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aeeac295",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv(\"results/y_logistic_regression_on_labels_066968.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc94b18",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b756f55fe797ce5a3b3491a8045903d781b4ca2e5e9dbd4284da291141e560b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
